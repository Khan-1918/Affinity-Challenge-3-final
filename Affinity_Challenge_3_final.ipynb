{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp5AfM8aB1Bz",
        "outputId": "8060fe87-1d96-4e8b-8aab-7a085beba778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# Load datasets\n",
        "orders_path = '/content/drive/MyDrive/Affinity Task 3/orders.csv'  # Replace with your file path\n",
        "submission_path = '/content/drive/MyDrive/Affinity Task 3/c3_submission_form.csv'  # Replace with your file path\n",
        "orders_data = pd.read_csv(orders_path)\n",
        "submission_data = pd.read_csv(submission_path)\n",
        "\n",
        "# Drop irrelevant columns\n",
        "columns_to_drop = [\n",
        "    'dim_order_key', 'dim_organization_key', 'dim_product_key',\n",
        "    'dim_status_key', 'dim_team_key', 'dim_user_key', 'dsp',\n",
        "    'src_modified_by', 'src_modified_on', 'src_record_updated_time',\n",
        "    'src_record_updated_time_utc', 'stage_id', 'status_key',\n",
        "    'primary_manager_user_key', 'secondry_manager_user_key'\n",
        "]\n",
        "orders_data_cleaned = orders_data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Process date/time columns conditionally\n",
        "date_columns = ['customer_intime', 'startdate', 'order_due_time', 'order_in_time']\n",
        "for col in date_columns:\n",
        "    if col in orders_data_cleaned.columns:\n",
        "        orders_data_cleaned[col] = pd.to_datetime(orders_data_cleaned[col], errors='coerce')\n",
        "        orders_data_cleaned[f'{col}_dayofweek'] = orders_data_cleaned[col].dt.dayofweek\n",
        "        orders_data_cleaned[f'{col}_hourofday'] = orders_data_cleaned[col].dt.hour\n",
        "        orders_data_cleaned = orders_data_cleaned.drop(columns=[col])\n",
        "\n",
        "# Frequency encode categorical columns\n",
        "categorical_columns = orders_data_cleaned.select_dtypes(include=['object']).columns\n",
        "for col in categorical_columns:\n",
        "    freq_encoding = orders_data_cleaned[col].value_counts(normalize=True)\n",
        "    orders_data_cleaned[col] = orders_data_cleaned[col].map(freq_encoding)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(orders_data_cleaned.drop(columns=['is_late'], errors='ignore'))\n",
        "y_train = orders_data_cleaned['is_late']\n",
        "\n",
        "# Train the Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Preprocess test data\n",
        "submission_data_cleaned = submission_data.drop(columns=columns_to_drop, errors='ignore')\n",
        "for col in date_columns:\n",
        "    if col in submission_data_cleaned.columns:\n",
        "        submission_data_cleaned[col] = pd.to_datetime(submission_data_cleaned[col], errors='coerce')\n",
        "        submission_data_cleaned[f'{col}_dayofweek'] = submission_data_cleaned[col].dt.dayofweek\n",
        "        submission_data_cleaned[f'{col}_hourofday'] = submission_data_cleaned[col].dt.hour\n",
        "        submission_data_cleaned = submission_data_cleaned.drop(columns=[col])\n",
        "\n",
        "# Frequency encoding for categorical columns in the test dataset\n",
        "for col in categorical_columns:\n",
        "    if col in submission_data_cleaned.columns:  # Only process if the column exists\n",
        "        freq_encoding = orders_data_cleaned[col].value_counts(normalize=True)\n",
        "        submission_data_cleaned[col] = submission_data_cleaned[col].map(freq_encoding)\n",
        "\n",
        "# Align columns between training and test datasets\n",
        "missing_cols = set(orders_data_cleaned.columns) - set(submission_data_cleaned.columns)\n",
        "for col in missing_cols:\n",
        "    submission_data_cleaned[col] = 0  # Add missing columns with default value\n",
        "\n",
        "extra_cols = set(submission_data_cleaned.columns) - set(orders_data_cleaned.columns)\n",
        "submission_data_cleaned = submission_data_cleaned.drop(columns=extra_cols, errors='ignore')\n",
        "\n",
        "# Match feature names explicitly\n",
        "train_features = orders_data_cleaned.drop(columns=['is_late'], errors='ignore').columns\n",
        "submission_data_cleaned = submission_data_cleaned[train_features]\n",
        "\n",
        "# Impute missing values in the test dataset\n",
        "X_test_submission = imputer.transform(submission_data_cleaned)\n",
        "\n",
        "# Predict outcomes for the test dataset\n",
        "submission_predictions = rf_model.predict(X_test_submission)\n",
        "\n",
        "# Add predictions to the submission dataset\n",
        "submission_data['is_late'] = submission_predictions\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "output_path = 'submission_predictions.csv'  # Output file path\n",
        "submission_data[['dim_order_key', 'is_late']].to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Dp2xyhCEjQ",
        "outputId": "df00a77c-1e43-4405-d536-3d6355c0e63f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to submission_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# For training data\n",
        "y_pred_train = rf_model.predict(X_train)  # Predict on the training set\n",
        "f1_training_score = f1_score(y_train, y_pred_train)  # Calculate F1 Score for training data\n",
        "print(f\"F1 Score on Training Data: {f1_training_score}\")\n",
        "\n",
        "# For test data\n",
        "y_pred_test = rf_model.predict(X_test_submission)  # Predict on the test set\n",
        "# NOTE: Test data doesn't have ground truth labels; this is just for consistency.\n",
        "# You need true labels (if available) for test F1 score calculation.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw0YWDEMFJqU",
        "outputId": "f8e841ba-dad1-471a-e92b-96f7d3142cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score on Training Data: 0.9972013551333039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Cost Parameters\n",
        "cost_fp = 300  # Cost of assigning extra resources for predicted late orders\n",
        "cost_fn = 700  # Penalty for failing to predict late deliveries\n",
        "\n",
        "# Predicted probabilities for the test dataset\n",
        "submission_predictions_proba = rf_model.predict_proba(X_test_submission)[:, 1]  # Probability of being late\n",
        "\n",
        "# Define thresholds to evaluate\n",
        "thresholds = np.linspace(0.1, 0.9, 9)  # Evaluate thresholds from 0.1 to 0.9\n",
        "total_costs = []\n",
        "\n",
        "# Simulate predictions and calculate total cost for each threshold\n",
        "for threshold in thresholds:\n",
        "    # Adjust predictions based on the threshold\n",
        "    adjusted_predictions = (submission_predictions_proba >= threshold).astype(int)\n",
        "\n",
        "    # Calculate confusion matrix components\n",
        "    tn, fp, fn, tp = confusion_matrix(submission_data['is_late'], adjusted_predictions).ravel()\n",
        "\n",
        "    # Compute total cost\n",
        "    total_cost = (fp * cost_fp) + (fn * cost_fn)\n",
        "    total_costs.append((threshold, total_cost))\n",
        "\n",
        "# Find the optimal threshold with minimum cost\n",
        "optimal_threshold, min_cost = min(total_costs, key=lambda x: x[1])\n",
        "\n",
        "# Output results\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "print(f\"Minimum Total Cost: ${min_cost}\")\n",
        "\n",
        "# Final predictions using the optimal threshold\n",
        "final_predictions = (submission_predictions_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# Evaluate the model at the optimal threshold\n",
        "print(\"\\nClassification Report at Optimal Threshold:\")\n",
        "print(classification_report(submission_data['is_late'], final_predictions))\n",
        "\n",
        "# Cost breakdown\n",
        "predicted_late = sum(final_predictions)\n",
        "actual_late = sum(submission_data['is_late'])\n",
        "cost_late_orders = predicted_late * cost_fp\n",
        "cost_failed_predictions = sum((submission_data['is_late'] != final_predictions) & (submission_data['is_late'] == 1)) * cost_fn\n",
        "\n",
        "print(f\"Predicted Late Orders: {predicted_late}\")\n",
        "print(f\"Actual Late Orders: {actual_late}\")\n",
        "print(f\"Cost of Assigning Extra Resources: ${cost_late_orders}\")\n",
        "print(f\"Cost of Failed Predictions (Penalties): ${cost_failed_predictions}\")\n",
        "print(f\"Total Cost at Optimal Threshold: ${cost_late_orders + cost_failed_predictions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBmT47S6KV9k",
        "outputId": "567470c7-3b11-47ab-bf63-c398d285d13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Threshold: 0.5\n",
            "Minimum Total Cost: $36600\n",
            "\n",
            "Classification Report at Optimal Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.93      0.96      1698\n",
            "        True       0.93      1.00      0.97      1700\n",
            "\n",
            "    accuracy                           0.96      3398\n",
            "   macro avg       0.97      0.96      0.96      3398\n",
            "weighted avg       0.97      0.96      0.96      3398\n",
            "\n",
            "Predicted Late Orders: 1822\n",
            "Actual Late Orders: 1700\n",
            "Cost of Assigning Extra Resources: $546600\n",
            "Cost of Failed Predictions (Penalties): $0\n",
            "Total Cost at Optimal Threshold: $546600\n"
          ]
        }
      ]
    }
  ]
}